<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>gilgi.org (Posts about Word2vec)</title><link>https://gilgi.org/</link><description></description><atom:link href="https://gilgi.org/categories/word2vec.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2020 &lt;a href="mailto:site@gilgi.org"&gt;gilgi&lt;/a&gt; </copyright><lastBuildDate>Sat, 23 May 2020 20:33:04 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Creating Dota 2 hero embeddings with Word2vec</title><link>https://gilgi.org/blog/dota-hero-embedding/</link><dc:creator>gilgi</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="https://gilgi.org/images/blog/dota-hero-embedding.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;One of the coolest results in natural language processing is the success of word embedding models like &lt;a href="https://en.wikipedia.org/wiki/Word2vec"&gt;Word2vec&lt;/a&gt;. These models are able to extract rich semantic information from words using surprisingly simple models like &lt;a href="https://en.wikipedia.org/wiki/Bag-of-words_model#CBOW"&gt;CBOW&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/N-gram#Skip-gram"&gt;skip-gram&lt;/a&gt;. What if we could use these generic modelling strategies to learn embeddings for something completely different - say, Dota 2 heroes.&lt;/p&gt;
&lt;p&gt;In this post, we'll use the &lt;a href="https://docs.opendota.com/"&gt;OpenDota API&lt;/a&gt; to collect data from professional Dota 2 matches and use &lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; to train a Word2vec-like model for hero embeddings.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/gilgi/gilgi.github.com/blob/src/posts/dota_hero_embedding.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gilgi.org/blog/dota-hero-embedding/"&gt;Read more…&lt;/a&gt; (17 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Dota 2</category><category>embedding</category><category>keras</category><category>machine learning</category><category>notebook</category><category>Python</category><category>Word2vec</category><guid>https://gilgi.org/blog/dota-hero-embedding/</guid><pubDate>Sun, 27 May 2018 04:00:00 GMT</pubDate></item></channel></rss>